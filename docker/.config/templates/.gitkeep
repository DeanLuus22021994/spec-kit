# Templates Directory
# Configuration templates for generating environment-specific files
#
# This directory is reserved for:
# - Configuration file templates
# - Docker Compose template variants
# - Workflow templates
# - GPU-enabled service templates
#
# Planned templates:
# - docker-compose.gpu.template.yml: GPU-enabled Docker Compose
# - service.gpu.template.yml: GPU-accelerated service template
# - workflow.gpu.template.yml: Self-hosted GPU runner workflow
# - environment.template.yml: Environment variable template
# - cuda.template.yml: CUDA configuration template
#
# Template Variables:
# - ${CUDA_VERSION}: CUDA toolkit version (default: 13.0)
# - ${PYTORCH_VERSION}: PyTorch version (default: 2.9.1+cu130)
# - ${COMPUTE_CAPABILITY}: GPU compute capability (default: 8.6)
# - ${GPU_MEMORY}: GPU memory limit (default: 6G)
# - ${GPU_DEVICE}: CUDA device ID (default: 0)
#
# Usage:
# Templates are processed by tools/cli.py to generate
# environment-specific configuration files.
#
# GPU Template Example:
# ```yaml
# gpu:
#   enabled: true
#   device: "cuda:${GPU_DEVICE}"
#   cuda_version: "${CUDA_VERSION}"
#   memory_limit: "${GPU_MEMORY}"
# ```
#
# Self-Hosted Runner Configuration:
# - Label: self-hosted-gpu
# - Token Required: No (already registered)
# - Pre-installed: CUDA 13.0, PyTorch 2.9.1+cu130
# - See .config/environment.yml for full configuration
